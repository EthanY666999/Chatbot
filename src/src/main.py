from openai import OpenAI
from .config import OPENAI_API_KEY, CHAT_MODEL  # æˆ– MODELï¼ˆçœ‹ä½ é€‰æ‹©çš„å‘½åï¼‰
from .prompt import SYSTEM_PROMPT
from .memory import VectorMemory, ChatMemory

def main():
    """
    ä¸€ä¸ªæœ€å°å¯è¿è¡Œçš„å‘½ä»¤è¡Œ Chatbotã€‚
    æ”¯æŒï¼š
      - è¿ç»­å¯¹è¯è®°å¿†
      - é€€å‡ºå‘½ä»¤ï¼ˆexit / quitï¼‰
      - è‡ªåŠ¨è¯»å– .env é‡Œçš„ OPENAI_API_KEY
    """
    # åˆå§‹åŒ–å®¢æˆ·ç«¯ä¸è®°å¿†
    client = OpenAI(api_key=OPENAI_API_KEY)
    memory = ChatMemory(max_turns=10)  # çŸ­æœŸä¼šè¯
    vmem = VectorMemory()   

    print("ğŸ¤– Chatbot å·²å¯åŠ¨ï¼Œè¾“å…¥ 'exit' é€€å‡ºã€‚\n")

    # å¾ªç¯å¯¹è¯
    while True:
        user_input = input("ä½ ï¼š").strip()
        if user_input.lower() in {"exit", "quit"}:
            print("ğŸ‘‹ å†è§ï¼")
            break

        # å­˜å…¥ç”¨æˆ·è¾“å…¥
        memory.add("user", user_input)

        # æ„é€ ä¸Šä¸‹æ–‡
        messages = [{"role": "system", "content": SYSTEM_PROMPT}] + memory.get()

        try:
            # è°ƒç”¨ OpenAI æ¥å£
            response = client.chat.completions.create(
                model=CHAT_MODEL,
                messages=messages,
            )
            reply = response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âš ï¸ å‡ºé”™äº†: {e}")
            continue

        # è¾“å‡ºå¹¶å­˜å…¥è®°å¿†
        print("Chatbotï¼š", reply, "\n")
        memory.add("assistant", reply)


if __name__ == "__main__":
    main()